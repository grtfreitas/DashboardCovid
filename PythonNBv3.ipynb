{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL to Dashboard: Using Python, PostgreSQL and Power BI to create a Covid Dashboard using up to date data.\n",
    "\n",
    "This project aims to showcase my skills to create a Covid Dashboard using data from the ECDE - European Centre for Disease Prevention and Control. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the postgres database connection\n",
    "engine = create_engine('postgresql+psycopg2://postgres:postgres@localhost:5432/CaseDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Getting Data and converting to Dataframe\n",
    "\n",
    "def JsonUrlToDf(url):\n",
    "    return pd.DataFrame(requests.get(url).json())\n",
    "\n",
    "def CsvToDf(url):\n",
    "    return pd.DataFrame(pd.read_csv(url))\n",
    "\n",
    "def ExcelToDf(url):\n",
    "    return pd.DataFrame(pd.read_excel(url))\n",
    "\n",
    "################# SQL related functions\n",
    "\n",
    "#SQL database connection\n",
    "\n",
    "def DBInfo(dbengine,TableName,SchemaName,IfExists):\n",
    "    return [dbengine,TableName,SchemaName,IfExists]\n",
    "\n",
    "#Send Export DataFrame    \n",
    "\n",
    "def ToSql(data,args):\n",
    "   data.to_sql(args[1],con=args[0],schema=args[2],if_exists=args[3],index=False)\n",
    "\n",
    "def CovidDataToSql(data,args=[engine,\"CovidData\",\"CaseSchema\",\"replace\"]):\n",
    "   data.to_sql(args[1],con=args[0],schema=args[2],if_exists=args[3],index=False)\n",
    "\n",
    "def CountriesDataToSql(data,args=[engine,\"CountriesData\",\"CaseSchema\",\"replace\"]):\n",
    "   data.to_sql(args[1],con=args[0],schema=args[2],if_exists=args[3],index=False)\n",
    "\n",
    "def QuerySql(sql,dbengine):\n",
    "    return pd.read_sql(sql,con=dbengine)\n",
    "    \n",
    "#Query data and return as DataFrame\n",
    "\n",
    "def FromSqltoDf(data,arg):\n",
    "    return pd.DataFrame(pd.read_sql(data,con=arg))\n",
    "\n",
    "################# Cleaning Data\n",
    "\n",
    "def CleaningCovidData(data):\n",
    "    return data.drop(['source','country_code','note'],axis=1)\n",
    "\n",
    "def CleaningCountriesData(data):\n",
    "    data.rename(columns={\"Country\":\"country\"},inplace=True)\n",
    "    data['country'] = data['country'].astype(str).str[0:-1]\n",
    "    return data\n",
    "\n",
    "################# Pipelines\n",
    "\n",
    "def PipelineCovidDataToSql(data):\n",
    "    return (JsonUrlToDf(data)\n",
    "    .pipe(CleaningCovidData)\n",
    "    .pipe(CovidDataToSql)\n",
    "    )\n",
    "\n",
    "def PipelineCovidDataToDf(data):\n",
    "    return (JsonUrlToDf(data)\n",
    "    .pipe(CleaningCovidData)\n",
    "    )\n",
    "\n",
    "def PipelineCountriesDataToSql(data):\n",
    "    return (CsvToDf(data)\n",
    "    .pipe(CleaningCountriesData)\n",
    "    .pipe(CountriesDataToSql)\n",
    "    )  \n",
    "\n",
    "def ReturnNonDuplicatesDf(data1,data2):\n",
    "    return pd.concat([data1,data2]).drop_duplicates(keep=False)\n",
    "\n",
    "## Preparing data to be used in Power BI\n",
    "def VisualData(data,arg):\n",
    "    return FromSqltoDf(data,arg).pivot_table(index=['country','continent','population'],columns='indicator',values=['IndicatorCountPer100k','cumulative_count']).reset_index().set_axis(['Country','Continent','Population','CasesPer100k','DeathsPer100k','TotalCases','TotalDeaths'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Table in Postgres with Covid Data from url with json format\n",
    "PipelineCovidDataToSql(\"https://opendata.ecdc.europa.eu/covid19/nationalcasedeath/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create table in Postgres with countries data from local file with csv format\n",
    "#### Improve: get data directly from kaggle using API\n",
    "PipelineCountriesDataToSql(\"C:/Users/GFreitas/Downloads/Revamped DDEC/datasource2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query the data from Postgres and compare to new data and append only the non-duplicate data\n",
    "## Can be pipelined even more!\n",
    "SQL = 'select * from \"CaseSchema\".\"CovidData\"'\n",
    "ToSql(ReturnNonDuplicatesDf(FromSqltoDf(SQL,engine),PipelineCovidDataToDf(\"https://opendata.ecdc.europa.eu/covid19/nationalcasedeath/json\")),DBInfo(engine,\"CovidData\",\"CaseSchema\",\"append\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query the data from Postgres and compare to new data and append only the data with higher date than the highest date from table, also replace old records with same country, date and indicator as a new one.\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enrich data coparing it with HDI / IHDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modeling data to be used to create visuals with SQL and Python\n",
    "SQL = 'select CV.\"country\", CV.\"continent\", a.\"max_date\", a.\"indicator\",  CV.\"cumulative_count\", CV.\"population\",(CV.\"cumulative_count\"/CV.\"population\"*100000) as \"IndicatorCountPer100k\"   from \"CaseSchema\".\"CovidData\" as CV INNER JOIN(SELECT CVI.\"country\", CVI.\"indicator\", max(CVI.\"year_week\") as \"max_date\" from \"CaseSchema\".\"CovidData\" as CVI group by CVI.\"country\",CVI.\"indicator\" ORDER BY CVI.\"country\")a ON CV.\"year_week\" = a.\"max_date\" WHERE CV.\"indicator\" = a.\"indicator\" and a.\"country\" = CV.\"country\" ORDER BY CV.\"country\"'\n",
    "ToSql(VisualData(SQL,engine),DBInfo(engine,\"VisualData\",\"CaseSchema\",\"replace\"))\n",
    "\n",
    "## conectar PowerBI com view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Generic Formulas\n",
    "\n",
    "\n",
    "# def ToSql(data,args):\n",
    "#    data.to_sql(args[1],con=args[0],schema=args[2],if_exists=args[3],index=False)\n",
    "\n",
    "#def CreateCountPer100kColumn(data,name):\n",
    "#    data[name] = (pd.to_numeric(data['cumulative_count'],errors='coerce') / data.population)*100000\n",
    "#   return data\n",
    "\n",
    "#def SeparateDataByIndicator(data,column,indicator):\n",
    "#    return data[data[column] == indicator].drop(column,axis=1).reset_index(drop=True)\n",
    "\n",
    "#def ToCsv(data,arg):\n",
    "#    data.to_csv(arg+\".csv\",index=False)\n",
    "\n",
    "##########################\n",
    "\n",
    "## Exercise 6 Alternative: Modeling the data to be used to create visuals with Python only.\n",
    "\n",
    "#def SeparateDataByIndicatorCases(data):\n",
    "#    return data[data['indicator'] == 'cases'].drop('indicator',axis=1).reset_index(drop=True)\n",
    "\n",
    "#def SeparateDataByIndicatorDeaths(data):\n",
    "#   return data[data['indicator'] == 'deaths'].drop('indicator',axis=1).reset_index(drop=True)\n",
    "\n",
    "#def CreateCountPer100kCases(data):\n",
    "#    data['CasesPer100k'] = (pd.to_numeric(data['cumulative_count'],errors='coerce') / data.population)*100000\n",
    "#    return data.rename(columns={'cumulative_count':'CMLCases'})\n",
    "\n",
    "#def CreateCountPer100kDeaths(data):\n",
    "#    data['DeathsPer100k'] = (pd.to_numeric(data['cumulative_count'],errors='coerce') / data.population)*100000\n",
    "#    return data.drop(['continent','population'],axis=1).rename(columns={'cumulative_count':'CMLDeaths'})\n",
    "\n",
    "#def LatestCovidData(data):\n",
    "#    data['year_week'] = data['year_week'].str.replace('-','').astype(int)\n",
    "#    Filtro1 = data['year_week'].loc[data['year_week'].idxmax()]\n",
    "#    LatestDate = data[data['year_week'] == Filtro1].fillna(\"null\")\n",
    "#    return LatestDate[LatestDate['country_code'] != \"null\"].drop(['country_code','weekly_count','year_week','source','rate_14_day','note'],axis=1)\n",
    "\n",
    "#def PipelineLatestCasesData(data):\n",
    "#    return (\n",
    "#    PipelineCovidData(data)\n",
    "#    .pipe(LatestCovidData)\n",
    "#    .pipe(SeparateDataByIndicatorCases)\n",
    "#    .pipe(CreateCountPer100kCases)\n",
    "#    )\n",
    "\n",
    "#def PipelineLatestDeathsData(data):\n",
    "#    return (\n",
    "#    PipelineCovidData(data)\n",
    "#    .pipe(LatestCovidData)\n",
    "#    .pipe(SeparateDataByIndicatorDeaths)\n",
    "#    .pipe(CreateCountPer100kDeaths)\n",
    "#    )\n",
    "\n",
    "#def MergeData(data1,data2,on):\n",
    "#    return data1.merge(data2,on=on)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06ae1dda8fee8c8bf6dfcdcb636c895090d29abf4576d9b794df1ec2743d0fa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
